{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation Notebook \n",
    "---\n",
    "\n",
    "We can now move on to evaluation of the model. The recorded metrics looked quite good during training with F1, recall, and precision scores being comparable to previous runs. Overall, this would seem to indicate that model performance has not been negatively impacted by changes to the preprocessing code. Due to the nature of this prediction task, however, a purely quantitative analysis based on metrics like recall or precision isn't sufficient. What ultimately matters is the quality of the predicted tags, which requires a bit of human judgement. \n",
    "\n",
    "In this notebook we will actually examine the predicted tags on the evaluation dataset as well as tag the same test file as was previously tagged for quality assurance (see `Tag_DE_test_csv.ipynb`). This will allow us to make a qualitative comparison to the previous model. \n",
    "\n",
    "This evaluation procudure highlights one of the main difficulties in productionizing this particular model. We need to be able to find ways to automate parts of this evaluation process so that we can effectively monitor the model's performance in production. This will be need to be a key area of focus after the creation of the training pipeline. Unfortunately, it may simply be the case that some degree of human evaluation is still required at periodic intervals in order to gauge the performance of the model. \n",
    "\n",
    "The notebook is structured as follows: \n",
    "\n",
    "    A. Examining Predictions on the Eval Set\n",
    "    B. Tagging a test set of ~80 Examples "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "import pprint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tfx\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import apache_beam as beam\n",
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "from matplotlib import pyplot as plt\n",
    "\n",
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from google.cloud import storage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Output of the preprocessing\n",
    "TRANSFORM_DIR = 'gs://ml-sandbox-tagging-tfx-experiments/preprocessing_notebook'\n",
    "TRANSFORMED_TRAIN = 'train_transformed'\n",
    "TRANSFORMED_TEST = 'test_transformed'\n",
    "LABEL_FILE_NAME = 'tags'\n",
    "VOCAB_FILE_NAME = 'vocab'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** These metrics were copied from the original training notebooks for fair model comparsions in case they different from the keras metrics. In the future, we will probably just use the [standard metrics from Keras](https://www.tensorflow.org/api_docs/python/tf/keras/metrics). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recall_score(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_score(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_score(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** This was copied from the training notebook. In the future, we would not need to repeat this code here when using TFX. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_transform_output = tft.TFTransformOutput(TRANSFORM_DIR)\n",
    "\n",
    "tag_file = tf_transform_output.vocabulary_file_by_name(LABEL_FILE_NAME)\n",
    "tags_df = pd.read_csv(tag_file, header=None)\n",
    "NUM_TAGS = len(tags_df)\n",
    "\n",
    "vocab_file = tf_transform_output.vocabulary_file_by_name(VOCAB_FILE_NAME)\n",
    "vocab_df = pd.read_csv(vocab_file, header=None)\n",
    "VOCAB_SIZE = len(vocab_df)\n",
    "\n",
    "MAX_STRING_LENGTH = 277\n",
    "\n",
    "def create_tag_lookup_table():\n",
    "    table = tf.lookup.StaticVocabularyTable(\n",
    "        tf.lookup.TextFileInitializer(\n",
    "            tag_file,\n",
    "            key_dtype=tf.string, key_index=tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "            value_dtype=tf.int64, value_index=tf.lookup.TextFileIndex.LINE_NUMBER,\n",
    "            delimiter=None),\n",
    "        num_oov_buckets=1)\n",
    "    return table\n",
    "\n",
    "table = create_tag_lookup_table()\n",
    "\n",
    "def label_transform(x, y):\n",
    "    \"\"\"Use the number of classes to convert the sparse tag indicies to dense\"\"\"\n",
    "    # Need to add one for out-of-vocabulary tags in eval dataset\n",
    "    return (x, tf.cast(tf.sparse.to_indicator(table.lookup(y), vocab_size=NUM_TAGS + 1), tf.int32))\n",
    "\n",
    "def _input_fn(file_pattern, tf_transform_output, batch_size=64, shuffle=True, epochs=None):\n",
    "    \"\"\"Generates features and label for tuning/training.\n",
    "    Args:\n",
    "        file_pattern: input tfrecord file pattern.\n",
    "        tf_transform_output: A TFTransformOutput.\n",
    "        batch_size: representing the number of consecutive elements of\n",
    "          returned dataset to combine in a single batch\n",
    "    Returns:\n",
    "        A dataset that contains (features, indices) tuple where features\n",
    "        is a dictionary of Tensors, and indices is a single Tensor of\n",
    "        label indices.\n",
    "    \"\"\"\n",
    "    transformed_feature_spec = (\n",
    "        tf_transform_output.transformed_feature_spec().copy()\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transformed_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=shuffle,\n",
    "        label_key='series_ep_tags',\n",
    "        num_epochs=epochs\n",
    "    )\n",
    "    return dataset.map(label_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = load_model('gs://ml-sandbox-tagging-tfx-experiments/models/1/',\n",
    "                   custom_objects={'precision_score': precision_score,\n",
    "                                   'recall_score': recall_score,\n",
    "                                   'f1': f1})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = pd.read_csv('gs://ml-sandbox-tagging-tfx-experiments/models/training_statistics.csv', \n",
    "                     index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7f425c5403d0>]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['loss'])\n",
    "plt.plot(history['val_loss'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training curves honestly look pretty bad. Model is not generalizing to the eval dataset. May need to try another model or rethink the approach. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>loss</th>\n",
       "      <th>precision_score</th>\n",
       "      <th>recall_score</th>\n",
       "      <th>f1</th>\n",
       "      <th>val_loss</th>\n",
       "      <th>val_precision_score</th>\n",
       "      <th>val_recall_score</th>\n",
       "      <th>val_f1</th>\n",
       "      <th>lr</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.012735</td>\n",
       "      <td>0.771525</td>\n",
       "      <td>0.393911</td>\n",
       "      <td>0.490293</td>\n",
       "      <td>0.011670</td>\n",
       "      <td>0.660315</td>\n",
       "      <td>0.369182</td>\n",
       "      <td>0.466203</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.004773</td>\n",
       "      <td>0.908104</td>\n",
       "      <td>0.682437</td>\n",
       "      <td>0.773890</td>\n",
       "      <td>0.010969</td>\n",
       "      <td>0.685465</td>\n",
       "      <td>0.431948</td>\n",
       "      <td>0.524783</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.003289</td>\n",
       "      <td>0.936991</td>\n",
       "      <td>0.781907</td>\n",
       "      <td>0.849892</td>\n",
       "      <td>0.010937</td>\n",
       "      <td>0.681690</td>\n",
       "      <td>0.459060</td>\n",
       "      <td>0.544093</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.002533</td>\n",
       "      <td>0.950384</td>\n",
       "      <td>0.831648</td>\n",
       "      <td>0.885395</td>\n",
       "      <td>0.011184</td>\n",
       "      <td>0.687577</td>\n",
       "      <td>0.471237</td>\n",
       "      <td>0.554293</td>\n",
       "      <td>0.00050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002023</td>\n",
       "      <td>0.961353</td>\n",
       "      <td>0.860864</td>\n",
       "      <td>0.906991</td>\n",
       "      <td>0.010895</td>\n",
       "      <td>0.706737</td>\n",
       "      <td>0.484603</td>\n",
       "      <td>0.570167</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.001863</td>\n",
       "      <td>0.964994</td>\n",
       "      <td>0.870738</td>\n",
       "      <td>0.914312</td>\n",
       "      <td>0.011009</td>\n",
       "      <td>0.704529</td>\n",
       "      <td>0.485291</td>\n",
       "      <td>0.569727</td>\n",
       "      <td>0.00005</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       loss  precision_score  recall_score        f1  val_loss  \\\n",
       "0  0.012735         0.771525      0.393911  0.490293  0.011670   \n",
       "1  0.004773         0.908104      0.682437  0.773890  0.010969   \n",
       "2  0.003289         0.936991      0.781907  0.849892  0.010937   \n",
       "3  0.002533         0.950384      0.831648  0.885395  0.011184   \n",
       "4  0.002023         0.961353      0.860864  0.906991  0.010895   \n",
       "5  0.001863         0.964994      0.870738  0.914312  0.011009   \n",
       "\n",
       "   val_precision_score  val_recall_score    val_f1       lr  \n",
       "0             0.660315          0.369182  0.466203  0.00050  \n",
       "1             0.685465          0.431948  0.524783  0.00050  \n",
       "2             0.681690          0.459060  0.544093  0.00050  \n",
       "3             0.687577          0.471237  0.554293  0.00050  \n",
       "4             0.706737          0.484603  0.570167  0.00005  \n",
       "5             0.704529          0.485291  0.569727  0.00005  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(history)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Precision is slightly lower than previous model, but recall is higher and overall f1 score is higher. \n",
    "\n",
    "In the original training notebook, \"thresholds\" on the validation metrics were defined: 0.7 for precision, 0.4 for recall, and 0.5 for f1. Even though these thresholds were perhaps a bit arbitrary, it is certainly promising that we were able to hit these thresholds during the training. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### **A. Examining Predictions on the Evaluation Set**\n",
    "\n",
    "Though the loss curves from training look quite bad, the quantitative performance ultimately might not matter so much. Let's take look at the decoded predictions on the evaluation set, this should give us a better indication of what is going on. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:AutoGraph could not transform <function label_transform at 0x7f42607a4b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n",
      "WARNING: AutoGraph could not transform <function label_transform at 0x7f42607a4b00> and will run it as-is.\n",
      "Please report this to the TensorFlow team. When filing the bug, set the verbosity to 10 (on Linux, `export AUTOGRAPH_VERBOSITY=10`) and attach the full output.\n",
      "Cause: 'arguments' object has no attribute 'posonlyargs'\n",
      "To silence this warning, decorate the function with @tf.autograph.experimental.do_not_convert\n"
     ]
    }
   ],
   "source": [
    "# Shuffle is true so we can look at random examples\n",
    "eval_dataset = _input_fn(\n",
    "    file_pattern=os.path.join(TRANSFORM_DIR, TRANSFORMED_TEST + '*'),\n",
    "    tf_transform_output=tf_transform_output,\n",
    "    batch_size=1,\n",
    "    epochs=1,\n",
    "    shuffle=True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Add in empty string so we can easily decode the inputs\n",
    "vocab_df.loc[len(vocab_df)] = ''\n",
    "tags_df.loc[len(tags_df)] = ''\n",
    "\n",
    "def decode_features(features):\n",
    "    feat_array = features['features'].numpy().reshape(-1,)\n",
    "    words = vocab_df.iloc[feat_array].values\n",
    "    synopsis = (' ').join(np.hstack(words))\n",
    "    \n",
    "    return synopsis\n",
    "\n",
    "def decode_true_tags(tags):\n",
    "    tag_idx = np.argwhere(tags == 1)[:, 1]\n",
    "    decoded_tags = np.hstack(tags_df.iloc[tag_idx].values)\n",
    "    \n",
    "    return decoded_tags\n",
    "\n",
    "def decode_predictions(predictions, top_n=10, thresh=None):\n",
    "    sorted_predicted_tags = np.argsort(predictions, axis=1)[:, ::-1][0]\n",
    "    \n",
    "    decoded_predictions = np.hstack(tags_df.iloc[sorted_predicted_tags].values)\n",
    "    prediction_frame = pd.DataFrame(zip(decoded_predictions, \n",
    "                                        predictions[0][sorted_predicted_tags]), \n",
    "                                    columns=['Predicted Tag', 'Probability'])\n",
    "    prediction_frame['Probability'] = prediction_frame['Probability'].round(2)\n",
    "    \n",
    "    if top_n:\n",
    "        prediction_frame = prediction_frame.iloc[:top_n]\n",
    "        \n",
    "    if thresh:\n",
    "        prediction_frame = prediction_frame.loc[prediction_frame['Probability'] > thresh]\n",
    "        \n",
    "    return prediction_frame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** Eval dataset is shuffled, **rerun this cell** to look at different random samples! "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=================================== Synopsis ===================================\n",
      "die prinzessin glaubt einen geist gesehen zu haben und die paw patrol muss in quot mission paw royally  quot auf den grund gehen in quot pups save monkey  quot stiehlt bürgermeister  eine magische maske  wetter luftschiff wird von bürgermeister  gestohlen ein herd explodiert bei einem chili koch off und bürgermeister   scheint bereit zu sein die katzenausstellung von adventure bay zu gewinnen ein team von welpen angeführt vom energiegeladenen ryder ist immer bereit wenn es geht darum in der adventure bay zu helfen paw patrol ist in bewegung cartoons under paw patrol                                                                                                                                                                                   \n",
      "===================================== Tags =====================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>True Tags</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kids_cartoon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>under 5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kids_adventure</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kids_comedy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kids_animal</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kids_friendship</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kids_cgi_animation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kids_dogs</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            True Tags\n",
       "0        kids_cartoon\n",
       "1             under 5\n",
       "2      kids_adventure\n",
       "3         kids_comedy\n",
       "4         kids_animal\n",
       "5     kids_friendship\n",
       "6  kids_cgi_animation\n",
       "7           kids_dogs"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================ Predicted Tags ================================\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Predicted Tag</th>\n",
       "      <th>Probability</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>under 5</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>kids_cartoon</td>\n",
       "      <td>1.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>kids_adventure</td>\n",
       "      <td>0.99</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kids_seas_&amp;_oceans</td>\n",
       "      <td>0.29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kids_education</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>kids_animal</td>\n",
       "      <td>0.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>kids_cgi_animation</td>\n",
       "      <td>0.16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>kids_gaelic_language</td>\n",
       "      <td>0.05</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Predicted Tag  Probability\n",
       "0               under 5         1.00\n",
       "1          kids_cartoon         1.00\n",
       "2        kids_adventure         0.99\n",
       "3    kids_seas_&_oceans         0.29\n",
       "4        kids_education         0.25\n",
       "5           kids_animal         0.19\n",
       "6    kids_cgi_animation         0.16\n",
       "7  kids_gaelic_language         0.05"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "for features, tags in eval_dataset.take(1):\n",
    "    decoded_features = decode_features(features)\n",
    "    decoded_tags = decode_true_tags(tags)\n",
    "    decoded_tags = pd.DataFrame(decoded_tags, columns=['True Tags'])\n",
    "    \n",
    "    predictions = model.predict(features)\n",
    "    decoded_predictions = decode_predictions(predictions, top_n=len(decoded_tags))\n",
    "\n",
    "    \n",
    "    print('{:=^80}'.format(' Synopsis '))\n",
    "    print(decoded_features)\n",
    "    print('{:=^80}'.format(' Tags '))\n",
    "    display(decoded_tags)\n",
    "    print('{:=^80}'.format(' Predicted Tags '))\n",
    "    display(decoded_predictions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the most part, the predicted tags actually look quite good! The probabilities seem to be quite reasonable as well. \n",
    "\n",
    "Interestingly, there are some cases where some of the predicted tags makes sense but are not in the set of true tags. This is a pretty good sign! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "---\n",
    "\n",
    "### **B. Tagging A Test Set**\n",
    "\n",
    "We will now tag a test file sent over by DE product. This is the same set of examples that was tested with the previous iteration of the model. \n",
    "\n",
    "One important thing this test might help illuminate is how much predictions vary across different models. We would hope that the predictions are quite stable...\n",
    "\n",
    "**NOTE:** We are doing the tagging quite \"manually\" here. In the future, we'd probably want to handle this with the [TFX bulk inferrer](https://www.tensorflow.org/tfx/guide/bulkinferrer) component. This could come at the end of the training pipeline or could be leveraged as part of a separate evaluation pipeline. \n",
    "\n",
    "**NOTE:** We are also doing the pre-preprocessing quite manually. Hopefully we can avoid this in the future by incorporating these steps into the `preprocessing_fn` somehow. This will require some coordination to uncover the various formats we might see the data. \n",
    "\n",
    "We will tag the test set using the `saved_model_cli`. This will also allow us to see whether we can actually serve the model. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df = pd.read_csv(\"gs://ml-sandbox-101-tagging/data/raw/DE_Content_autotagging_syntax_test.csv\", index_col=0)\n",
    "\n",
    "test_df['clean_title'] = test_df.title.apply(lambda x: re.sub(r's\\de\\d',\"\",x.lower()).split(':')[0].strip())\n",
    "test_df['title_word'] = test_df.clean_title.apply(lambda x: x.strip().replace(' ','_'))\n",
    "\n",
    "test_df['combi'] = test_df.fillna(\"\")[['genre','subgenres','synopsis']].apply(lambda row: \" \".join(row), axis=1)\n",
    "\n",
    "temp = test_df.groupby('clean_title')['combi'].apply(\" \".join).to_frame().reset_index()\n",
    "temp = temp.rename(columns={'combi':'group_combi'})\n",
    "\n",
    "test_df = pd.merge(test_df,temp,on='clean_title',how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typ</th>\n",
       "      <th>uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>subgenres</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>notes</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>title_word</th>\n",
       "      <th>combi</th>\n",
       "      <th>group_combi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FTA</td>\n",
       "      <td>5654bc76-cdfb-4de4-8282-3c0dc4c0002f</td>\n",
       "      <td>Der Bachelor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfos ...</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>der bachelor</td>\n",
       "      <td>der_bachelor</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfo...</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FTA</td>\n",
       "      <td>a74d9bda-19cf-4d58-81a6-2cd80dc187b7</td>\n",
       "      <td>Deutschland sucht den Superstar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfos ...</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deutschland sucht den superstar</td>\n",
       "      <td>deutschland_sucht_den_superstar</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfo...</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FTA</td>\n",
       "      <td>dd59b73b-ff26-4e85-9d58-4410abf5cdca</td>\n",
       "      <td>Volle Kanne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Das ZDF-Magazin präsentiert prominente Gäste u...</td>\n",
       "      <td>['factual', 'news', 'asia', 'magazine', 'japan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volle kanne</td>\n",
       "      <td>volle_kanne</td>\n",
       "      <td>Das ZDF-Magazin präsentiert prominente Gäste...</td>\n",
       "      <td>Das ZDF-Magazin präsentiert prominente Gäste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FTA</td>\n",
       "      <td>0ae37637-5b48-402e-ae35-bd717ce7b142</td>\n",
       "      <td>Tagesschau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aktuelle Themen aus Politik, Wirtschaft, Kultu...</td>\n",
       "      <td>['news', 'politics', 'affairs', 'europe', 'cur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tagesschau</td>\n",
       "      <td>tagesschau</td>\n",
       "      <td>Aktuelle Themen aus Politik, Wirtschaft, Kul...</td>\n",
       "      <td>Aktuelle Themen aus Politik, Wirtschaft, Kul...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FTA</td>\n",
       "      <td>b6fe2170-112f-47c8-b134-a809ef675a7c</td>\n",
       "      <td>Kollaps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noteinsatz auf einem Dortmunder Kinderspielpla...</td>\n",
       "      <td>['united kingdom', 'crime', 'family &amp; relation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kollaps</td>\n",
       "      <td>kollaps</td>\n",
       "      <td>Noteinsatz auf einem Dortmunder Kinderspielp...</td>\n",
       "      <td>Noteinsatz auf einem Dortmunder Kinderspielp...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   typ                                  uuid                            title  \\\n",
       "0  FTA  5654bc76-cdfb-4de4-8282-3c0dc4c0002f                     Der Bachelor   \n",
       "1  FTA  a74d9bda-19cf-4d58-81a6-2cd80dc187b7  Deutschland sucht den Superstar   \n",
       "2  FTA  dd59b73b-ff26-4e85-9d58-4410abf5cdca                      Volle Kanne   \n",
       "3  FTA  0ae37637-5b48-402e-ae35-bd717ce7b142                       Tagesschau   \n",
       "4  FTA  b6fe2170-112f-47c8-b134-a809ef675a7c                          Kollaps   \n",
       "\n",
       "  genre subgenres                                           synopsis  \\\n",
       "0   NaN       NaN  Aus lizenzvertraglichen Gründen Programminfos ...   \n",
       "1   NaN       NaN  Aus lizenzvertraglichen Gründen Programminfos ...   \n",
       "2   NaN       NaN  Das ZDF-Magazin präsentiert prominente Gäste u...   \n",
       "3   NaN       NaN  Aktuelle Themen aus Politik, Wirtschaft, Kultu...   \n",
       "4   NaN       NaN  Noteinsatz auf einem Dortmunder Kinderspielpla...   \n",
       "\n",
       "                                                tags notes  \\\n",
       "0                                        no_synopsis   NaN   \n",
       "1                                        no_synopsis   NaN   \n",
       "2  ['factual', 'news', 'asia', 'magazine', 'japan...   NaN   \n",
       "3  ['news', 'politics', 'affairs', 'europe', 'cur...   NaN   \n",
       "4  ['united kingdom', 'crime', 'family & relation...   NaN   \n",
       "\n",
       "                       clean_title                       title_word  \\\n",
       "0                     der bachelor                     der_bachelor   \n",
       "1  deutschland sucht den superstar  deutschland_sucht_den_superstar   \n",
       "2                      volle kanne                      volle_kanne   \n",
       "3                       tagesschau                       tagesschau   \n",
       "4                          kollaps                          kollaps   \n",
       "\n",
       "                                               combi  \\\n",
       "0    Aus lizenzvertraglichen Gründen Programminfo...   \n",
       "1    Aus lizenzvertraglichen Gründen Programminfo...   \n",
       "2    Das ZDF-Magazin präsentiert prominente Gäste...   \n",
       "3    Aktuelle Themen aus Politik, Wirtschaft, Kul...   \n",
       "4    Noteinsatz auf einem Dortmunder Kinderspielp...   \n",
       "\n",
       "                                         group_combi  \n",
       "0    Aus lizenzvertraglichen Gründen Programminfo...  \n",
       "1    Aus lizenzvertraglichen Gründen Programminfo...  \n",
       "2    Das ZDF-Magazin präsentiert prominente Gäste...  \n",
       "3    Aktuelle Themen aus Politik, Wirtschaft, Kul...  \n",
       "4    Noteinsatz auf einem Dortmunder Kinderspielp...  "
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy() # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def serialize_example(feature):\n",
    "    input_example = {\n",
    "          'features': _bytes_feature(feature)\n",
    "    }\n",
    "    \n",
    "    example_proto = tf.train.Example(features=tf.train.Features(feature=input_example))\n",
    "    return example_proto.SerializeToString()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_features = test_df['group_combi'].values\n",
    "utf_encoded = np.array([feature.encode('utf-8') for feature in input_features])\n",
    "all_examples = [serialize_example(encoded) for encoded in utf_encoded]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"test_examples.pkl\", \"wb\") as test_file:\n",
    "    pickle.dump(all_examples, test_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Result for output key outputs:\n",
      "[[9.7040653e-02 1.2519845e-01 2.2040218e-01 ... 3.1982750e-02\n",
      "  3.1826735e-02 2.5292307e-02]\n",
      " [9.7040653e-02 1.2519845e-01 2.2040218e-01 ... 3.1982750e-02\n",
      "  3.1826735e-02 2.5292307e-02]\n",
      " [1.6833663e-02 4.6759248e-03 3.4187800e-01 ... 5.5816770e-04\n",
      "  8.0388784e-04 3.1393766e-04]\n",
      " ...\n",
      " [3.2249856e-01 8.9828765e-01 1.4528275e-02 ... 1.6888976e-04\n",
      "  2.0951033e-04 2.3210049e-04]\n",
      " [1.5592822e-01 1.3899651e-01 2.8662527e-01 ... 5.5059791e-03\n",
      "  7.0389509e-03 5.8575869e-03]\n",
      " [3.5311550e-02 4.2110473e-02 2.6585698e-01 ... 2.6392937e-04\n",
      "  7.2839856e-04 4.2319298e-04]]\n",
      "Output outputs is saved to ./outputs.npy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2020-10-15 07:19:31.660009: W tensorflow/stream_executor/platform/default/dso_loader.cc:59] Could not load dynamic library 'libcudart.so.10.1'; dlerror: libcudart.so.10.1: cannot open shared object file: No such file or directory; LD_LIBRARY_PATH: /usr/local/cuda/lib64:/usr/local/nccl2/lib:/usr/local/cuda/extras/CUPTI/lib64\n",
      "2020-10-15 07:19:31.660057: I tensorflow/stream_executor/cuda/cudart_stub.cc:29] Ignore above cudart dlerror if you do not have a GPU set up on your machine.\n",
      "2020-10-15 07:19:33.842151: I tensorflow/stream_executor/platform/default/dso_loader.cc:48] Successfully opened dynamic library libcuda.so.1\n",
      "2020-10-15 07:19:33.855924: E tensorflow/stream_executor/cuda/cuda_driver.cc:314] failed call to cuInit: CUDA_ERROR_NO_DEVICE: no CUDA-capable device is detected\n",
      "2020-10-15 07:19:33.855995: I tensorflow/stream_executor/cuda/cuda_diagnostics.cc:156] kernel driver does not appear to be running on this host (thomas-training): /proc/driver/nvidia/version does not exist\n",
      "2020-10-15 07:19:33.856631: I tensorflow/core/platform/cpu_feature_guard.cc:142] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN)to use the following CPU instructions in performance-critical operations:  AVX2 FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2020-10-15 07:19:33.866155: I tensorflow/core/platform/profile_utils/cpu_utils.cc:104] CPU Frequency: 2200000000 Hz\n",
      "2020-10-15 07:19:33.866586: I tensorflow/compiler/xla/service/service.cc:168] XLA service 0x560b3c0ad620 initialized for platform Host (this does not guarantee that XLA will be used). Devices:\n",
      "2020-10-15 07:19:33.866618: I tensorflow/compiler/xla/service/service.cc:176]   StreamExecutor device (0): Host, Default Version\n",
      "WARNING:tensorflow:From /opt/conda/lib/python3.7/site-packages/tensorflow/python/tools/saved_model_cli.py:444: load (from tensorflow.python.saved_model.loader_impl) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "This function will only be available through the v1 compatibility library as tf.compat.v1.saved_model.loader.load or tf.compat.v1.saved_model.load. There will be a new function for importing SavedModels in Tensorflow 2.0.\n",
      "INFO:tensorflow:Restoring parameters from gs://ml-sandbox-tagging-tfx-experiments/models/2/variables/variables\n"
     ]
    }
   ],
   "source": [
    "%%bash\n",
    "saved_model_cli run \\\n",
    "    --dir gs://ml-sandbox-tagging-tfx-experiments/models/2 \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def serving_default \\\n",
    "    --inputs \"examples=test_examples.pkl\" \\\n",
    "    --outdir \"./\" \\\n",
    "    --overwrite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = np.load('outputs.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.7040653e-02 1.2519845e-01 2.2040218e-01 ... 3.1982750e-02\n",
      "  3.1826735e-02 2.5292307e-02]\n",
      " [9.7040653e-02 1.2519845e-01 2.2040218e-01 ... 3.1982750e-02\n",
      "  3.1826735e-02 2.5292307e-02]\n",
      " [1.6833663e-02 4.6759248e-03 3.4187800e-01 ... 5.5816770e-04\n",
      "  8.0388784e-04 3.1393766e-04]\n",
      " ...\n",
      " [3.2249856e-01 8.9828765e-01 1.4528275e-02 ... 1.6888976e-04\n",
      "  2.0951033e-04 2.3210049e-04]\n",
      " [1.5592822e-01 1.3899651e-01 2.8662527e-01 ... 5.5059791e-03\n",
      "  7.0389509e-03 5.8575869e-03]\n",
      " [3.5311550e-02 4.2110473e-02 2.6585698e-01 ... 2.6392937e-04\n",
      "  7.2839856e-04 4.2319298e-04]]\n",
      "(89, 2597)\n",
      "89\n"
     ]
    }
   ],
   "source": [
    "print(predictions)\n",
    "print(predictions.shape)\n",
    "print(len(test_df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We were able to get predictions for the entire test set! Now to see if the predictions actually make sense..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_predicted_tags = np.argsort(predictions, axis=1)[:, ::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "probs = []\n",
    "\n",
    "tags_to_keep = 10\n",
    "\n",
    "for i, prediction in enumerate(predictions):\n",
    "    if test_df.tags.values[i] == 'no_synopsis':\n",
    "        results.append('no_synopsis')\n",
    "        probs.append('N/A')\n",
    "    else: \n",
    "        top_tags = np.hstack(tags_df.iloc[sorted_predicted_tags[i]].values[:tags_to_keep])\n",
    "        results.append(list(top_tags))\n",
    "\n",
    "        confidences = prediction[sorted_predicted_tags[i]][:tags_to_keep]\n",
    "        probs.append(confidences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_tag = pd.read_csv(\"gs://ml-sandbox-101-tagging/data/raw/DE_Content_autotagging_syntax_test_tagged.csv\", \n",
    "                           index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>typ</th>\n",
       "      <th>uuid</th>\n",
       "      <th>title</th>\n",
       "      <th>genre</th>\n",
       "      <th>subgenres</th>\n",
       "      <th>synopsis</th>\n",
       "      <th>tags</th>\n",
       "      <th>notes</th>\n",
       "      <th>clean_title</th>\n",
       "      <th>title_word</th>\n",
       "      <th>combi</th>\n",
       "      <th>group_combi</th>\n",
       "      <th>new_tags</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>FTA</td>\n",
       "      <td>5654bc76-cdfb-4de4-8282-3c0dc4c0002f</td>\n",
       "      <td>Der Bachelor</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfos ...</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>der bachelor</td>\n",
       "      <td>der_bachelor</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfo...</td>\n",
       "      <td>lizenzvertraglichen gründen programminfos verf...</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>FTA</td>\n",
       "      <td>a74d9bda-19cf-4d58-81a6-2cd80dc187b7</td>\n",
       "      <td>Deutschland sucht den Superstar</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfos ...</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>NaN</td>\n",
       "      <td>deutschland sucht den superstar</td>\n",
       "      <td>deutschland_sucht_den_superstar</td>\n",
       "      <td>Aus lizenzvertraglichen Gründen Programminfo...</td>\n",
       "      <td>lizenzvertraglichen gründen programminfos verf...</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>Low</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>FTA</td>\n",
       "      <td>dd59b73b-ff26-4e85-9d58-4410abf5cdca</td>\n",
       "      <td>Volle Kanne</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Das ZDF-Magazin präsentiert prominente Gäste u...</td>\n",
       "      <td>['factual', 'news', 'asia', 'magazine', 'japan...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>volle kanne</td>\n",
       "      <td>volle_kanne</td>\n",
       "      <td>Das ZDF-Magazin präsentiert prominente Gäste...</td>\n",
       "      <td>magazin präsentieren prominente gäste service ...</td>\n",
       "      <td>['food &amp; cooking', 'factual', 'tips &amp; advice',...</td>\n",
       "      <td>1H9L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>FTA</td>\n",
       "      <td>0ae37637-5b48-402e-ae35-bd717ce7b142</td>\n",
       "      <td>Tagesschau</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Aktuelle Themen aus Politik, Wirtschaft, Kultu...</td>\n",
       "      <td>['news', 'politics', 'affairs', 'europe', 'cur...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tagesschau</td>\n",
       "      <td>tagesschau</td>\n",
       "      <td>Aktuelle Themen aus Politik, Wirtschaft, Kul...</td>\n",
       "      <td>aktuell themen politik wirtschaft kultur sport...</td>\n",
       "      <td>['documentary', 'society', 'europe', 'factual'...</td>\n",
       "      <td>5H5L</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>FTA</td>\n",
       "      <td>b6fe2170-112f-47c8-b134-a809ef675a7c</td>\n",
       "      <td>Kollaps</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Noteinsatz auf einem Dortmunder Kinderspielpla...</td>\n",
       "      <td>['united kingdom', 'crime', 'family &amp; relation...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kollaps</td>\n",
       "      <td>kollaps</td>\n",
       "      <td>Noteinsatz auf einem Dortmunder Kinderspielp...</td>\n",
       "      <td>noteinsatz dortmunder kinderspielplatz sechsjä...</td>\n",
       "      <td>['documentary', 'family &amp; relationship', 'pare...</td>\n",
       "      <td>4H6L</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   typ                                  uuid                            title  \\\n",
       "0  FTA  5654bc76-cdfb-4de4-8282-3c0dc4c0002f                     Der Bachelor   \n",
       "1  FTA  a74d9bda-19cf-4d58-81a6-2cd80dc187b7  Deutschland sucht den Superstar   \n",
       "2  FTA  dd59b73b-ff26-4e85-9d58-4410abf5cdca                      Volle Kanne   \n",
       "3  FTA  0ae37637-5b48-402e-ae35-bd717ce7b142                       Tagesschau   \n",
       "4  FTA  b6fe2170-112f-47c8-b134-a809ef675a7c                          Kollaps   \n",
       "\n",
       "  genre subgenres                                           synopsis  \\\n",
       "0   NaN       NaN  Aus lizenzvertraglichen Gründen Programminfos ...   \n",
       "1   NaN       NaN  Aus lizenzvertraglichen Gründen Programminfos ...   \n",
       "2   NaN       NaN  Das ZDF-Magazin präsentiert prominente Gäste u...   \n",
       "3   NaN       NaN  Aktuelle Themen aus Politik, Wirtschaft, Kultu...   \n",
       "4   NaN       NaN  Noteinsatz auf einem Dortmunder Kinderspielpla...   \n",
       "\n",
       "                                                tags notes  \\\n",
       "0                                        no_synopsis   NaN   \n",
       "1                                        no_synopsis   NaN   \n",
       "2  ['factual', 'news', 'asia', 'magazine', 'japan...   NaN   \n",
       "3  ['news', 'politics', 'affairs', 'europe', 'cur...   NaN   \n",
       "4  ['united kingdom', 'crime', 'family & relation...   NaN   \n",
       "\n",
       "                       clean_title                       title_word  \\\n",
       "0                     der bachelor                     der_bachelor   \n",
       "1  deutschland sucht den superstar  deutschland_sucht_den_superstar   \n",
       "2                      volle kanne                      volle_kanne   \n",
       "3                       tagesschau                       tagesschau   \n",
       "4                          kollaps                          kollaps   \n",
       "\n",
       "                                               combi  \\\n",
       "0    Aus lizenzvertraglichen Gründen Programminfo...   \n",
       "1    Aus lizenzvertraglichen Gründen Programminfo...   \n",
       "2    Das ZDF-Magazin präsentiert prominente Gäste...   \n",
       "3    Aktuelle Themen aus Politik, Wirtschaft, Kul...   \n",
       "4    Noteinsatz auf einem Dortmunder Kinderspielp...   \n",
       "\n",
       "                                         group_combi  \\\n",
       "0  lizenzvertraglichen gründen programminfos verf...   \n",
       "1  lizenzvertraglichen gründen programminfos verf...   \n",
       "2  magazin präsentieren prominente gäste service ...   \n",
       "3  aktuell themen politik wirtschaft kultur sport...   \n",
       "4  noteinsatz dortmunder kinderspielplatz sechsjä...   \n",
       "\n",
       "                                            new_tags confidence  \n",
       "0                                        no_synopsis        Low  \n",
       "1                                        no_synopsis        Low  \n",
       "2  ['food & cooking', 'factual', 'tips & advice',...       1H9L  \n",
       "3  ['documentary', 'society', 'europe', 'factual'...       5H5L  \n",
       "4  ['documentary', 'family & relationship', 'pare...       4H6L  "
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "previous_tag.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "previous_tag['predicted_tags_new_model'] = results\n",
    "previous_tag['confidence_new_model'] = probs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>new_tags</th>\n",
       "      <th>confidence</th>\n",
       "      <th>predicted_tags_new_model</th>\n",
       "      <th>confidence_new_model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>Low</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>Low</td>\n",
       "      <td>no_synopsis</td>\n",
       "      <td>N/A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>['food &amp; cooking', 'factual', 'tips &amp; advice',...</td>\n",
       "      <td>1H9L</td>\n",
       "      <td>[competition, tips &amp; advice, game show, fashio...</td>\n",
       "      <td>[0.53762394, 0.39052236, 0.38325572, 0.3472697...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>['documentary', 'society', 'europe', 'factual'...</td>\n",
       "      <td>5H5L</td>\n",
       "      <td>[politics, society, news, factual, history, th...</td>\n",
       "      <td>[0.8382405, 0.77600294, 0.47971675, 0.4418002,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>['documentary', 'family &amp; relationship', 'pare...</td>\n",
       "      <td>4H6L</td>\n",
       "      <td>[work life balance, family &amp; relationship, dom...</td>\n",
       "      <td>[0.39917642, 0.39805096, 0.39259452, 0.3304067...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>['sci-fi', 'thriller', 'action', 'imaginative'...</td>\n",
       "      <td>6H4L</td>\n",
       "      <td>[thriller, action, sci-fi, imaginative, tense,...</td>\n",
       "      <td>[0.68279994, 0.5923272, 0.58054745, 0.5728739,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>['thriller', 'action', 'espionage &amp; spying', '...</td>\n",
       "      <td>2H8L</td>\n",
       "      <td>[thriller, crime, drama, action, mystery, murd...</td>\n",
       "      <td>[0.9380072, 0.7798225, 0.658823, 0.6076958, 0....</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>['thriller', 'mystery', 'crime', 'dark', 'murd...</td>\n",
       "      <td>High</td>\n",
       "      <td>[thriller, drama, crime, tense, murder, psycho...</td>\n",
       "      <td>[0.90553546, 0.89828765, 0.82583225, 0.7653932...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>['adult', 'exclude_from_recs', 'lust &amp; desires...</td>\n",
       "      <td>3H7L</td>\n",
       "      <td>[dating &amp; relationship, factual, united kingdo...</td>\n",
       "      <td>[0.4641252, 0.28662527, 0.26620573, 0.26237163...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>['adult', 'lust &amp; desires', 'erotic', 'risque'...</td>\n",
       "      <td>5H5L</td>\n",
       "      <td>[islands, dating &amp; relationship, adult, friend...</td>\n",
       "      <td>[0.6266698, 0.4410608, 0.3875999, 0.35444665, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             new_tags confidence  \\\n",
       "0                                         no_synopsis        Low   \n",
       "1                                         no_synopsis        Low   \n",
       "2   ['food & cooking', 'factual', 'tips & advice',...       1H9L   \n",
       "3   ['documentary', 'society', 'europe', 'factual'...       5H5L   \n",
       "4   ['documentary', 'family & relationship', 'pare...       4H6L   \n",
       "..                                                ...        ...   \n",
       "84  ['sci-fi', 'thriller', 'action', 'imaginative'...       6H4L   \n",
       "85  ['thriller', 'action', 'espionage & spying', '...       2H8L   \n",
       "86  ['thriller', 'mystery', 'crime', 'dark', 'murd...       High   \n",
       "87  ['adult', 'exclude_from_recs', 'lust & desires...       3H7L   \n",
       "88  ['adult', 'lust & desires', 'erotic', 'risque'...       5H5L   \n",
       "\n",
       "                             predicted_tags_new_model  \\\n",
       "0                                         no_synopsis   \n",
       "1                                         no_synopsis   \n",
       "2   [competition, tips & advice, game show, fashio...   \n",
       "3   [politics, society, news, factual, history, th...   \n",
       "4   [work life balance, family & relationship, dom...   \n",
       "..                                                ...   \n",
       "84  [thriller, action, sci-fi, imaginative, tense,...   \n",
       "85  [thriller, crime, drama, action, mystery, murd...   \n",
       "86  [thriller, drama, crime, tense, murder, psycho...   \n",
       "87  [dating & relationship, factual, united kingdo...   \n",
       "88  [islands, dating & relationship, adult, friend...   \n",
       "\n",
       "                                 confidence_new_model  \n",
       "0                                                 N/A  \n",
       "1                                                 N/A  \n",
       "2   [0.53762394, 0.39052236, 0.38325572, 0.3472697...  \n",
       "3   [0.8382405, 0.77600294, 0.47971675, 0.4418002,...  \n",
       "4   [0.39917642, 0.39805096, 0.39259452, 0.3304067...  \n",
       "..                                                ...  \n",
       "84  [0.68279994, 0.5923272, 0.58054745, 0.5728739,...  \n",
       "85  [0.9380072, 0.7798225, 0.658823, 0.6076958, 0....  \n",
       "86  [0.90553546, 0.89828765, 0.82583225, 0.7653932...  \n",
       "87  [0.4641252, 0.28662527, 0.26620573, 0.26237163...  \n",
       "88  [0.6266698, 0.4410608, 0.3875999, 0.35444665, ...  \n",
       "\n",
       "[89 rows x 4 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(previous_tag[['new_tags', 'confidence', 'predicted_tags_new_model', 'confidence_new_model']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ipywidgets import interact, fixed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_old_new_tags(df, idx):\n",
    "    synopsis = df.iloc[idx]['group_combi']\n",
    "    old_probs = df.iloc[idx]['confidence']\n",
    "    \n",
    "    try:\n",
    "        old_tags = eval(df.iloc[idx]['new_tags'])\n",
    "    except:\n",
    "        old_tags = df.iloc[idx]['new_tags']\n",
    "    new_tags = df.iloc[idx]['predicted_tags_new_model']\n",
    "    confidence_new_model = df.iloc[idx]['confidence_new_model']\n",
    "    \n",
    "    comparison_frame = pd.DataFrame(np.vstack((old_tags, new_tags, confidence_new_model)).T, \n",
    "                        columns=['Tags Old Model', 'Tags New Model', 'Probs New Model'])\n",
    "    \n",
    "    print('{:=^80}'.format(' Synopsis '))\n",
    "    print(synopsis)\n",
    "    print('{:=^80}'.format(' Model Comparison '))\n",
    "    print(\"OLD PROBS: \", old_probs)\n",
    "    display(comparison_frame)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3551935ffb6c426ba53355079d4c2f6e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "interactive(children=(Dropdown(description='idx', options=(0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 1…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "<function __main__.display_old_new_tags(df, idx)>"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "interact(display_old_new_tags, df=fixed(previous_tag), idx=range(len(previous_tag)))"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
