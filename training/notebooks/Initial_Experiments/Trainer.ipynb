{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Notebook \n",
    "---\n",
    "\n",
    "Now that we've done preprocessing, we'd like to confirm that we haven't negatively impacted model performance. Recall that the overall goal of rewriting the preprocessing and training as we've done is to replicate the behavior of the existing model as best as possible while simplifying productionization and operationalization. \n",
    "\n",
    "The preprocessing_fn and the trainer module are the main things we have to worry about when writing the TFX pipeline, much of everything else (e.g. schema generation, passing data between components) is handled by the framework. The code in this notebook will be pulled out to create the trainer module"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import tempfile\n",
    "import pprint\n",
    "import os\n",
    "import tensorflow as tf\n",
    "import tfx\n",
    "import tensorflow_transform as tft\n",
    "import tensorflow_transform.beam as tft_beam\n",
    "from tensorflow_transform.tf_metadata import dataset_metadata\n",
    "from tensorflow_transform.tf_metadata import schema_utils\n",
    "from sklearn.model_selection import train_test_split\n",
    "import apache_beam as beam\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from google.cloud import storage\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Dataset Creation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "TRANSFORM_DIR = 'gs://ml-sandbox-tagging-tfx-experiments/preprocessing_notebook'\n",
    "TRANSFORMED_TRAIN = 'train_transformed'\n",
    "TRANSFORMED_TEST = 'test_transformed'\n",
    "LABEL_FILE_NAME = 'tags'\n",
    "VOCAB_FILE_NAME = 'vocab'\n",
    "\n",
    "tf_transform_output = tft.TFTransformOutput(TRANSFORM_DIR)\n",
    "\n",
    "NUM_TAGS = tf_transform_output.vocabulary_size_by_name(LABEL_FILE_NAME)\n",
    "tag_file = tf_transform_output.vocabulary_file_by_name('tags')\n",
    "\n",
    "vocab_file = tf_transform_output.vocabulary_file_by_name('vocab')\n",
    "vocab_df = pd.read_csv(vocab_file, header=None)\n",
    "VOCAB_SIZE = tf_transform_output.vocabulary_size_by_name(VOCAB_FILE_NAME)\n",
    "\n",
    "MAX_STRING_LENGTH = 277\n",
    "\n",
    "def create_tag_lookup_table():\n",
    "    table = tf.lookup.StaticVocabularyTable(\n",
    "        tf.lookup.TextFileInitializer(\n",
    "            tag_file,\n",
    "            key_dtype=tf.string, key_index=tf.lookup.TextFileIndex.WHOLE_LINE,\n",
    "            value_dtype=tf.int64, value_index=tf.lookup.TextFileIndex.LINE_NUMBER,\n",
    "            delimiter=None),\n",
    "        num_oov_buckets=1)\n",
    "    return table\n",
    "\n",
    "table = create_tag_lookup_table()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_transform(x, y):\n",
    "    \"\"\"Use the number of classes to convert the sparse tag indicies to dense\"\"\"\n",
    "    # Need to add one for out-of-vocabulary tags in eval dataset\n",
    "    return (x, tf.cast(tf.sparse.to_indicator(table.lookup(y), vocab_size=NUM_TAGS + 1), tf.int32))\n",
    "\n",
    "def _input_fn(file_pattern, tf_transform_output, batch_size=64, shuffle=True, epochs=None):\n",
    "    \"\"\"Generates features and label for tuning/training.\n",
    "    Args:\n",
    "        file_pattern: input tfrecord file pattern.\n",
    "        tf_transform_output: A TFTransformOutput.\n",
    "        batch_size: representing the number of consecutive elements of\n",
    "          returned dataset to combine in a single batch\n",
    "    Returns:\n",
    "        A dataset that contains (features, indices) tuple where features\n",
    "        is a dictionary of Tensors, and indices is a single Tensor of\n",
    "        label indices.\n",
    "    \"\"\"\n",
    "    transformed_feature_spec = (\n",
    "        tf_transform_output.transformed_feature_spec().copy()\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transformed_feature_spec,\n",
    "        reader=tf.data.TFRecordDataset,\n",
    "        shuffle=shuffle,\n",
    "        label_key='series_ep_tags',\n",
    "        num_epochs=epochs\n",
    "    )\n",
    "    return dataset.map(label_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# example creation of the dataset\n",
    "train_dataset = _input_fn(\n",
    "    file_pattern=os.path.join(TRANSFORM_DIR, TRANSFORMED_TRAIN + '*'),\n",
    "    tf_transform_output=tf_transform_output,\n",
    "    batch_size=64\n",
    ")\n",
    "\n",
    "eval_dataset = _input_fn(\n",
    "    file_pattern=os.path.join(TRANSFORM_DIR, TRANSFORMED_TEST + '*'),\n",
    "    tf_transform_output=tf_transform_output,\n",
    "    batch_size=64,\n",
    "    shuffle=False,\n",
    "    epochs=1\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Training**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import callbacks, layers\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILE_NAME = 'gs://ml-sandbox-101-tagging/data/processed/training_data/glove_data/glove_embedding_index.pkl'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE:** These custom metrics were copied from the previous training notebooks for a fair comparison to the old model. In the future, we will likely just use the keras default metrics. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import backend as K\n",
    "\n",
    "\n",
    "def recall_score(y_true, y_pred):\n",
    "    \"\"\"Recall metric.\n",
    "\n",
    "    Only computes a batch-wise average of recall.\n",
    "\n",
    "    Computes the recall, a metric for multi-label classification of\n",
    "    how many relevant items are selected.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "    recall = true_positives / (possible_positives + K.epsilon())\n",
    "    return recall\n",
    "\n",
    "\n",
    "def precision_score(y_true, y_pred):\n",
    "    \"\"\"Precision metric.\n",
    "\n",
    "    Only computes a batch-wise average of precision.\n",
    "\n",
    "    Computes the precision, a metric for multi-label classification of\n",
    "    how many selected items are relevant.\n",
    "    \"\"\"\n",
    "    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "    precision = true_positives / (predicted_positives + K.epsilon())\n",
    "    return precision\n",
    "\n",
    "\n",
    "def f1(y_true, y_pred):\n",
    "    def recall_score(y_true, y_pred):\n",
    "        \"\"\"Recall metric.\n",
    "\n",
    "        Only computes a batch-wise average of recall.\n",
    "\n",
    "        Computes the recall, a metric for multi-label classification of\n",
    "        how many relevant items are selected.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n",
    "        recall = true_positives / (possible_positives + K.epsilon())\n",
    "        return recall\n",
    "\n",
    "    def precision_score(y_true, y_pred):\n",
    "        \"\"\"Precision metric.\n",
    "\n",
    "        Only computes a batch-wise average of precision.\n",
    "\n",
    "        Computes the precision, a metric for multi-label classification of\n",
    "        how many selected items are relevant.\n",
    "        \"\"\"\n",
    "        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n",
    "        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n",
    "        precision = true_positives / (predicted_positives + K.epsilon())\n",
    "        return precision\n",
    "\n",
    "    precision = precision_score(y_true, y_pred)\n",
    "    recall = recall_score(y_true, y_pred)\n",
    "    return 2*((precision*recall)/(precision+recall+K.epsilon()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AutoTaggingModel:\n",
    "    def __init__(\n",
    "        self,\n",
    "        embedding_file: str,\n",
    "        embedding_dim: int,\n",
    "        train_embedding: bool,\n",
    "        output_size: int,\n",
    "        vocab_size: int,\n",
    "        max_string_length: int,\n",
    "    ):\n",
    "        self.__embedding_file = embedding_file\n",
    "        self.__embedding_dim = embedding_dim\n",
    "        self.__vocab_size = vocab_size\n",
    "        self.__train_embedding = train_embedding\n",
    "        self.__output_size = output_size\n",
    "        self.__max_string_length = max_string_length\n",
    "        \n",
    "        self.__initialize_embedding_matrix()\n",
    "    \n",
    "    def __initialize_embedding_matrix(self):\n",
    "        storage_client = storage.Client()\n",
    "        \n",
    "        # Better way to do this with os.path?\n",
    "        split_path = FILE_NAME.split('/')\n",
    "        bucket_name = split_path[2]\n",
    "        blob_name = ('/').join(split_path[3:])\n",
    "        \n",
    "        bucket = storage_client.bucket(bucket_name)\n",
    "        blob = bucket.blob(blob_name)\n",
    "        \n",
    "        pickle_in = blob.download_as_string()\n",
    "        file = pickle.loads(pickle_in)\n",
    "        \n",
    "        self.embedding_matrix = np.zeros((self.__vocab_size, \n",
    "                                     self.__embedding_dim))\n",
    "        \n",
    "        for i, word in enumerate(vocab_df.values):\n",
    "            embedding_vector = file.get(word[0])\n",
    "            if embedding_vector is not None:\n",
    "                self.embedding_matrix[i] = embedding_vector\n",
    "        \n",
    "    def embedding_layer(self):\n",
    "        return layers.Embedding(\n",
    "            input_dim=self.__vocab_size,\n",
    "            output_dim=self.__embedding_dim,\n",
    "            weights=[self.embedding_matrix],\n",
    "            input_length=self.__max_string_length,\n",
    "            trainable=self.__train_embedding,\n",
    "        )\n",
    "\n",
    "    def n_grams_channel(self, inputs, n_words_filter: int):\n",
    "        channel = layers.Conv2D(256, kernel_size=(n_words_filter, self.__embedding_dim), activation=\"relu\")(inputs)\n",
    "        channel_mp = layers.MaxPool2D(pool_size=(channel.shape[1], 1))(channel)\n",
    "        channel_final = layers.Flatten()(channel_mp)\n",
    "        return channel_final\n",
    "    \n",
    "    def define_model(self):\n",
    "        inputs = layers.Input(shape=(self.__max_string_length,), name='features')\n",
    "        embedding = self.embedding_layer()(inputs) \n",
    "        channel_inputs = layers.Reshape(target_shape=(self.__max_string_length, self.__embedding_dim, 1))(embedding)\n",
    "        channel1_final = self.n_grams_channel(channel_inputs, 3)\n",
    "        channel2_final = self.n_grams_channel(channel_inputs, 4)\n",
    "        channel3_final = self.n_grams_channel(channel_inputs, 5)\n",
    "        channels_final = layers.Concatenate()(\n",
    "            [channel1_final, channel2_final, channel3_final]\n",
    "        )\n",
    "        channels_final = layers.Dropout(rate=0.4)(channels_final)\n",
    "        channels_final = layers.Dense(2000, \"relu\")(channels_final)\n",
    "        predictions = layers.Dense(self.__output_size, \"sigmoid\")(channels_final)\n",
    "        model = Model(inputs=inputs, outputs=predictions)\n",
    "\n",
    "        return model\n",
    "\n",
    "    def get_model(self):\n",
    "        strategy = tf.distribute.MirroredStrategy()\n",
    "        with strategy.scope():\n",
    "            model = self.define_model()\n",
    "            \n",
    "            metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "            metrics = [precision_score, recall_score, f1]\n",
    "            model.compile(\n",
    "                optimizer=tf.keras.optimizers.Adam(learning_rate=0.0005),\n",
    "                loss=BinaryCrossentropy(),\n",
    "                metrics=metrics,\n",
    "            )\n",
    "        return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = AutoTaggingModel(\n",
    "    embedding_dim=300,\n",
    "    train_embedding=True,\n",
    "    embedding_file=FILE_NAME,\n",
    "    output_size=NUM_TAGS + 1,\n",
    "    vocab_size=VOCAB_SIZE + 1,\n",
    "    max_string_length=MAX_STRING_LENGTH\n",
    ").get_model()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previous training of model after 8 epochs:\n",
    "\n",
    "loss: 0.0031 - recall_score: 0.7846 - precision_score: 0.9444 - f1: 0.8570 - val_loss: 0.0099 - val_recall_score: 0.4392 - val_precision_score: 0.7245 - val_f1: 0.5467"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "early_stopping_callback = callbacks.EarlyStopping(monitor='val_loss',\n",
    "    min_delta=0.0001,\n",
    "    patience=4,\n",
    "    verbose=0,  \n",
    "    mode='auto',  \n",
    "    restore_best_weights=True)  \n",
    "\n",
    "reduce_lr = callbacks.ReduceLROnPlateau(\n",
    "    monitor='val_loss', factor=0.1, patience=2, verbose=0, mode='auto',\n",
    "    min_delta=0.0001\n",
    ") \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    train_dataset, \n",
    "    validation_data=eval_dataset,\n",
    "    steps_per_epoch=1400, \n",
    "    epochs=40, \n",
    "    callbacks=[early_stopping_callback, reduce_lr]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training looks quite good! We are able to reach similar levels on each of the metrics as we did with the previous model (see `Glove_embedding.ipynb` notebook). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(history.history).to_csv('models/training_statistics.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Saving Model with TF Transform for Serving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "    \"\"\"Returns a function that parses a serialized tf.Example.\"\"\"\n",
    "\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "\n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(serialized_tf_examples):\n",
    "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "        feature_spec = tf_transform_output.raw_feature_spec()\n",
    "        feature_spec.pop('series_ep_tags')\n",
    "        \n",
    "        parsed_features = tf.io.parse_example(\n",
    "            serialized_tf_examples, feature_spec\n",
    "        )\n",
    "\n",
    "        transformed_features = model.tft_layer(parsed_features)\n",
    "\n",
    "        outputs = model(transformed_features)\n",
    "        return {\"outputs\": outputs}\n",
    "\n",
    "    return serve_tf_examples_fn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "signatures = {\n",
    "    \"serving_default\": _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(\n",
    "        tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n",
    "    ),\n",
    "}\n",
    "model.save(\n",
    "    'models/2', save_format=\"tf\", signatures=signatures\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil -m cp -r models/ gs://ml-sandbox-tagging-tfx-experiments/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf models/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "saved_model_cli show \\\n",
    "    --dir gs://ml-sandbox-tagging-tfx-experiments/models/2 \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def serving_default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seems to be some GPU related issue that prevents calling the model with the `saved_model_cli` from within the same GPU VM used to train the model. When running from another notebook this works fine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "saved_model_cli run \\\n",
    "    --dir gs://ml-sandbox-tagging-tfx-experiments/models/2 \\\n",
    "    --tag_set serve \\\n",
    "    --signature_def serving_default \\\n",
    "    --input_exprs 'examples=[b\"\\n*\\n(\\n\\x08features\\x12\\x1c\\n\\x1a\\n\\x18klassifiziere mich bitte\"]'"
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-2-3-gpu.2-3.m56",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-2-3-gpu.2-3:m56"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
