{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import tensorflow_hub as hub\n",
    "import tensorflow as tf\n",
    "import tensorflow_text as tf_text\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_transform as tft\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow.keras import callbacks, layers\n",
    "\n",
    "from tensorflow.keras.losses import BinaryCrossentropy\n",
    "import tensorflow_text\n",
    "import tensorflow_hub as hub\n",
    "from tensorflow.keras.models import Model, Sequential\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.metrics import Precision, Recall\n",
    "\n",
    "# TODO: Add these in config instead of hard-coding\n",
    "TFHUB_HANDLE_PREPROCESSOR = \"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\"\n",
    "TFHUB_HANDLE_ENCODER = \"https://tfhub.dev/tensorflow/small_bert/bert_en_uncased_L-4_H-512_A-8/1\"\n",
    "\n",
    "def _gzip_reader_fn(filenames):\n",
    "    \"\"\"Small utility returning a record reader that can read gzip'ed fies\"\"\"\n",
    "    return tf.data.TFRecordDataset(filenames, compression_type=\"GZIP\")\n",
    "\n",
    "def _input_fn(file_pattern, tf_transform_output, batch_size=64, shuffle=True, epochs=None):\n",
    "    \"\"\"Generates features and label for tuning/training.\n",
    "    Args:\n",
    "        file_pattern: input tfrecord file pattern.\n",
    "        tf_transform_output: A TFTransformOutput.\n",
    "        batch_size: representing the number of consecutive elements of\n",
    "          returned dataset to combine in a single batch\n",
    "    Returns:\n",
    "        A dataset that contains (features, indices) tuple where features\n",
    "        is a dictionary of Tensors, and indices is a single Tensor of\n",
    "        label indices.\n",
    "    \"\"\"\n",
    "    transformed_feature_spec = (\n",
    "        tf_transform_output.transformed_feature_spec().copy()\n",
    "    )\n",
    "\n",
    "    dataset = tf.data.experimental.make_batched_features_dataset(\n",
    "        file_pattern=file_pattern,\n",
    "        batch_size=batch_size,\n",
    "        features=transformed_feature_spec,\n",
    "        reader=_gzip_reader_fn,\n",
    "        shuffle=shuffle,\n",
    "        label_key='tags_xf',\n",
    "        num_epochs=epochs\n",
    "    )\n",
    "    return dataset\n",
    "\n",
    "def build_bert_tagger(num_labels):\n",
    "    # TODO: think about alternative architecture\n",
    "    text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name='synopsis')\n",
    "    preprocessing_layer = hub.KerasLayer(TFHUB_HANDLE_PREPROCESSOR, name='preprocessing')\n",
    "    encoder_inputs = preprocessing_layer(text_input)\n",
    "    encoder = hub.KerasLayer(TFHUB_HANDLE_ENCODER, trainable=True, name='BERT_encoder')\n",
    "    outputs = encoder(encoder_inputs)\n",
    "    net = outputs['pooled_output']\n",
    "    output = tf.keras.layers.Dense(num_labels, activation=\"sigmoid\")(net)\n",
    "    return tf.keras.Model(text_input, output)\n",
    "\n",
    "def get_compiled_model(num_labels):\n",
    "    # TODO: figure out more about optimizer \n",
    "    strategy = tf.distribute.MirroredStrategy()\n",
    "    with strategy.scope():\n",
    "        model = build_bert_tagger(num_labels)\n",
    "        metrics = [tf.keras.metrics.Precision(), tf.keras.metrics.Recall()]\n",
    "        # clipnorm only seems to work in TF 2.4 with distribution strategy \n",
    "        model.compile(\n",
    "            optimizer=tf.keras.optimizers.Adam(learning_rate=0.00003,\n",
    "                                               clipnorm=1,\n",
    "                                               epsilon=1e-8),\n",
    "            loss=BinaryCrossentropy(),\n",
    "            metrics=metrics,\n",
    "        )\n",
    "    return model\n",
    "\n",
    "def _get_serve_tf_examples_fn(model, tf_transform_output):\n",
    "    \"\"\"Returns a function that parses JSON input\"\"\"\n",
    "    # TODO: Create alternative serving function, especially if using evaluator\n",
    "    model.tft_layer = tf_transform_output.transform_features_layer()\n",
    "    \n",
    "    @tf.function\n",
    "    def serve_tf_examples_fn(raw_text):\n",
    "        \"\"\"Returns the output to be used in the serving signature.\"\"\"\n",
    "        reshaped_text = tf.reshape(raw_text, [-1, 1])\n",
    "        transformed_features = model.tft_layer({\"synopsis\": reshaped_text})\n",
    "\n",
    "        outputs = model(transformed_features)\n",
    "        return {\"outputs\": outputs}\n",
    "\n",
    "    return serve_tf_examples_fn\n",
    "\n",
    "def run_fn(fn_args):\n",
    "    \"\"\"Train the model based on given args\n",
    "    \n",
    "    Args:\n",
    "        fn_args: Holds args used to train the model as name/value pairs\n",
    "    \"\"\"\n",
    "    tf_transform_output = tft.TFTransformOutput(fn_args.transform_output)\n",
    "    # Not sure why its like this\n",
    "    # TODO: fix this, might be a version issue?\n",
    "    num_labels = fn_args.custom_config['num_labels']\n",
    "    \n",
    "    train_dataset = _input_fn(\n",
    "        file_pattern=fn_args.train_files,\n",
    "        tf_transform_output=tf_transform_output,\n",
    "        batch_size=256)\n",
    "    \n",
    "    model = get_compiled_model(num_labels)\n",
    "    \n",
    "    # TODO pass in epochs\n",
    "    history = model.fit(\n",
    "        train_dataset, \n",
    "        epochs=3,\n",
    "        steps_per_epoch=fn_args.train_steps // 3\n",
    "    )\n",
    "    \n",
    "    signatures = {\n",
    "        \"serving_default\": _get_serve_tf_examples_fn(model, tf_transform_output).get_concrete_function(\n",
    "            tf.TensorSpec(shape=[None], dtype=tf.string, name=\"examples\")\n",
    "        ),\n",
    "    }\n",
    "    \n",
    "    model.save(\n",
    "        fn_args.serving_model_dir, save_format=\"tf\", signatures=signatures\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "\n",
    "@dataclass\n",
    "class function_args:\n",
    "    \"\"\"Class for creating function args for run fn.\"\"\"\n",
    "    train_files: str\n",
    "    transform_output: str\n",
    "    serving_model_dir: str\n",
    "    train_steps: int\n",
    "    eval_steps: int\n",
    "    custom_config: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_files = \"gs://metadata-bucket-sky/tfx-metadata-dev-pipeline-output-5/metadata-dev/Transform/transformed_examples/1441/train/*\"\n",
    "transform_output = \"gs://metadata-bucket-sky/tfx-metadata-dev-pipeline-output-5/metadata-dev/Transform/transform_graph/1441/\"\n",
    "serving_model_dir = 'serving_test/'\n",
    "\n",
    "fn_args = function_args(train_files, transform_output, serving_model_dir, 25000, 0, {'num_labels': 408})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using MirroredStrategy with devices ('/job:localhost/replica:0/task:0/device:GPU:0', '/job:localhost/replica:0/task:0/device:GPU:1', '/job:localhost/replica:0/task:0/device:GPU:2', '/job:localhost/replica:0/task:0/device:GPU:3')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f33ad1e0050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:6 out of the last 6 calls to <function recreate_function.<locals>.restored_function_body at 0x7f33ad1e0050> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7f33ad1e0710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:7 out of the last 7 calls to <function recreate_function.<locals>.restored_function_body at 0x7f33ad1e0710> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has experimental_relax_shapes=True option that relaxes argument shapes that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/3\n",
      "8333/8333 [==============================] - 6026s 720ms/step - loss: 0.0553 - precision_2: 0.2842 - recall_2: 0.2105\n",
      "Epoch 2/3\n",
      "8333/8333 [==============================] - 5886s 706ms/step - loss: 0.0051 - precision_2: 0.9193 - recall_2: 0.8089\n",
      "Epoch 3/3\n",
      "8333/8333 [==============================] - 5909s 709ms/step - loss: 0.0036 - precision_2: 0.9363 - recall_2: 0.8661\n",
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 310). These functions will not be directly callable after loading.\n",
      "WARNING:absl:Found untraced functions such as restored_function_body, restored_function_body, restored_function_body, restored_function_body, restored_function_body while saving (showing 5 of 310). These functions will not be directly callable after loading.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: serving_test/assets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Assets written to: serving_test/assets\n"
     ]
    }
   ],
   "source": [
    "run_fn(fn_args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Copying file://serving_test/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://serving_test/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "==> NOTE: You are uploading one or more large file(s), which would run          \n",
      "significantly faster if you enable parallel composite uploads. This\n",
      "feature can be enabled by editing the\n",
      "\"parallel_composite_upload_threshold\" value in your .boto\n",
      "configuration file. However, note that if you do this large files will\n",
      "be uploaded as `composite objects\n",
      "<https://cloud.google.com/storage/docs/composite-objects>`_,which\n",
      "means that any user who downloads such objects will need to have a\n",
      "compiled crcmod installed (see \"gsutil help crcmod\"). This is because\n",
      "without a compiled crcmod, computing checksums on composite objects is\n",
      "so slow that gsutil disables downloads of composite objects.\n",
      "\n",
      "Copying file://serving_test/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://serving_test/assets/tags [Content-Type=application/octet-stream]...\n",
      "- [4 files][339.7 MiB/339.7 MiB]                                                \n",
      "==> NOTE: You are performing a sequence of gsutil operations that may\n",
      "run significantly faster if you instead use gsutil -m cp ... Please\n",
      "see the -m section under \"gsutil help options\" for further information\n",
      "about when gsutil -m can be advantageous.\n",
      "\n",
      "Copying file://serving_test/assets/vocab.txt [Content-Type=text/plain]...\n",
      "Copying file://serving_test/1611044279/saved_model.pb [Content-Type=application/octet-stream]...\n",
      "Copying file://serving_test/1611044279/variables/variables.data-00000-of-00001 [Content-Type=application/octet-stream]...\n",
      "Copying file://serving_test/1611044279/variables/variables.index [Content-Type=application/octet-stream]...\n",
      "Copying file://serving_test/1611044279/assets/tags [Content-Type=application/octet-stream]...\n",
      "Copying file://serving_test/1611044279/assets/vocab [Content-Type=application/octet-stream]...\n",
      "| [10 files][872.0 MiB/872.0 MiB]                                               \n",
      "Operation completed over 10 objects/872.0 MiB.                                   \n"
     ]
    }
   ],
   "source": [
    "!gsutil cp -r serving_test/ gs://metadata-bucket-sky/new_model/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m61",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m61"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
